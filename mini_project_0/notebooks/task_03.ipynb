{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "804da611",
   "metadata": {},
   "source": [
    "Import needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3f8131d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from utils.llm_client import LLMClient\n",
    "from utils.prompts import render\n",
    "from utils.llm_client import LLMClient\n",
    "from utils.login_utils import log_llm_call\n",
    "from utils.router import pick_model, should_use_reasoning_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1483731f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Reasoning Steps:\n",
      "\n",
      "1. **Define Base Score**: The base score for all SOS calls is 5.\n",
      "2. **Age Adjustment**: Add 2 points if the age is greater than 60 or less than 5.\n",
      "3. **Urgency Adjustment**: \n",
      "   - Add 3 points if the main need is 'Rescue' (life-threatening situation).\n",
      "   - Add 1 point if the main need is 'Insulin/Medicine'.\n",
      "4. **Calculate Priority Score**: Sum the base score and any applicable adjustments.\n",
      "\n",
      "## Apply to Each Case:\n",
      "\n",
      "### Case 1:\n",
      "- **ID**: 1, **Age**: 20-40, **Need**: Water, **Urgency**: No specific urgency mentioned.\n",
      "- **Score**: Base Score (5) = 5. No adjustments needed.\n",
      "- **Priority Score**: 5/10\n",
      "\n",
      "### Case 2:\n",
      "- **ID**: 2, **Age**: 75, **Need**: Insulin, **Urgency**: Missed dose, feeling faint.\n",
      "- **Score**: Base Score (5) + Age Adjustment (+2) + Need Adjustment (+1) = 5 + 2 + 1 = 8.\n",
      "- **Priority Score**: 8/10\n",
      "\n",
      "### Case 3:\n",
      "- **ID**: 3, **Age**: 10, 35, **Need**: Rescue, **Urgency**: Life-threatening situation.\n",
      "- **Score**: Base Score (5) + Need Adjustment (+3) = 5 + 3 = 8. \n",
      "  - **Age Adjustment**: Only applies if age is a single value or uniformly applies to all; here, one is under 18, but instructions are not clear on how to handle ranges or multiple ages for a single adjustment.\n",
      "- **Priority Score**: 8/10\n",
      "\n",
      "## Answer:\n",
      "\n",
      "- **Case 1**: Score: 5/10\n",
      "- **Case 2**: Score: 8/10\n",
      "- **Case 3**: Score: 8/10\n"
     ]
    }
   ],
   "source": [
    "model = pick_model(\"groq\", \"reason\")\n",
    "llm_client = LLMClient(\"groq\", model)\n",
    "\n",
    "with open(\"../data/Incidents.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    lines = f.readlines()\n",
    "    headers = [h for h in lines[0].split(\"|\")]\n",
    "\n",
    "records = []\n",
    "for line in lines[1:]:\n",
    "    if not line.strip():\n",
    "        continue\n",
    "    values = [v.strip() for v in line.split(\"|\")]\n",
    "    record = dict(zip(headers, values))\n",
    "    records.append(record)\n",
    "\n",
    "\n",
    "prompt_text, spec = render(\n",
    "    \"cot_reasoning.v2\",\n",
    "    role=\"SOS call analyzer\",\n",
    "    problem = records,\n",
    "    logic = \"Assign a Priority Score (1-10) based on Age Need and Urgency.Base Score: 5, +2 if Age > 60 or < 5, +3 if Need == Rescue (Life Threat), +1 if Need == Insulin/Medicine \",\n",
    "    output = \"Score: {score}/10\"\n",
    ")\n",
    "\n",
    "messages = [{\"role\": \"user\", \"content\": prompt_text}]\n",
    "response = llm_client.chat(messages, temperature=1.0)\n",
    "\n",
    "response_text = response[\"text\"]\n",
    "print(response_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc717986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Solution Paths for SOS Call Analyzer\n",
      "\n",
      "Given the problem, we have three distinct solution paths based on different priorities:\n",
      "\n",
      "1. **Branch 1: Save the highest score first (Greedy)**\n",
      "2. **Branch 2: Save closest first (speed)**\n",
      "3. **Branch 3: Save furthest first (Logistics)**\n",
      "\n",
      "Let's analyze each path.\n",
      "\n",
      "### Branch 1: Save the highest score first (Greedy)\n",
      "\n",
      "**Hypothesis:** Prioritize SOS calls based on a scoring system that considers the urgency and vulnerability of the situation.\n",
      "\n",
      "**Steps:**\n",
      "- Assign scores based on urgency and vulnerability:\n",
      "  - **Urgency Score (US):** \n",
      "    - Main Need: Water (2), Insulin (3), Rescue (1)\n",
      "  - **Vulnerability Score (VS):** \n",
      "    - Ages: 20-40 (1), 75 (3), 10, 35 (2)\n",
      "  - **Total Score (TS) = US + VS + People**\n",
      "- Calculate scores for each SOS call and sort them in descending order.\n",
      "\n",
      "**Intermediate Check:**\n",
      "- **SOS 1:** Main Need = Water, Ages = 20-40, People = 4, Score = 2 (US) + 1 (VS) + 4 (People) = 7\n",
      "- **SOS 2:** Main Need = Insulin, Ages = 75, People = 1, Score = 3 (US) + 3 (VS) + 1 (People) = 7\n",
      "- **SOS 3:** Main Need = Rescue, Ages = 10, 35, People = 2, Score = 1 (US) + 2 (VS) + 2 (People) = 5\n",
      "\n",
      "Sorted Order: SOS 1 & SOS 2 (tied), SOS 3\n",
      "\n",
      "### Branch 2: Save closest first (speed)\n",
      "\n",
      "**Hypothesis:** Prioritize SOS calls based on their location, assuming the closest ones are saved first to minimize response time.\n",
      "\n",
      "**Steps:**\n",
      "- Assume a base location.\n",
      "- Calculate distances or assume based on Area names (for simplicity, let's assume Gampaha is closer than Ja-Ela and Ragama).\n",
      "\n",
      "**Intermediate Check:**\n",
      "- **Assumed Order:** Gampaha, Ja-Ela, Ragama\n",
      "- **SOS Order:** SOS 1 (Gampaha), SOS 2 (Ja-Ela), SOS 3 (Ragama)\n",
      "\n",
      "### Branch 3: Save furthest first (Logistics)\n",
      "\n",
      "**Hypothesis:** Prioritize based on logistics and resource optimization, assuming saving the furthest first might be more efficient in terms of overall resource allocation.\n",
      "\n",
      "**Steps:**\n",
      "- Similar to Branch 2, assume distances.\n",
      "\n",
      "**Intermediate Check:**\n",
      "- **SOS Order:** SOS 3 (Ragama), SOS 2 (Ja-Ela), SOS 1 (Gampaha)\n",
      "\n",
      "### Exploration and Selection\n",
      "\n",
      "**Branch 1 (Greedy):** \n",
      "- Tied for first: SOS 1 & SOS 2, then SOS 3.\n",
      "\n",
      "**Branch 2 (Closest First):** \n",
      "- Order: SOS 1, SOS 2, SOS 3.\n",
      "\n",
      "**Branch 3 (Furthest First):** \n",
      "- Order: SOS 3, SOS 2, SOS 1.\n",
      "\n",
      "### Best Path Selection\n",
      "\n",
      "Considering the urgency and immediate impact, **Branch 1: Save the highest score first (Greedy)** seems to balance urgency and vulnerability effectively. However, both SOS 1 and SOS 2 have the same score. Given that SOS 2 involves a diabetic person who missed a dose and is feeling faint, which might escalate quickly, and considering age vulnerability, prioritizing SOS 2 first could be critical.\n",
      "\n",
      "**Final Order (Greedy with slight adjustment for critical conditions):** \n",
      "1. SOS 2 (Ja-Ela, diabetic, high vulnerability)\n",
      "2. SOS 1 (Gampaha, water need, stable but multiple people)\n",
      "3. SOS 3 (Ragama, rescue needed, immediate action)\n",
      "\n",
      "**Answer:**\n",
      "Based on the analysis, the best initial response order should prioritize the diabetic person, then those in need of water, and finally those requiring rescue.\n",
      "\n",
      "**Order:** \n",
      "1. **SOS 2: Ja-Ela** \n",
      "2. **SOS 1: Gampaha** \n",
      "3. **SOS 3: Ragama**\n"
     ]
    }
   ],
   "source": [
    "model = pick_model(\"groq\", \"reason\")\n",
    "llm_client = LLMClient(\"groq\", model)\n",
    "\n",
    "with open(\"../data/Incidents.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    lines = f.readlines()\n",
    "    headers = [h for h in lines[0].split(\"|\")]\n",
    "\n",
    "records = []\n",
    "for line in lines[1:]:\n",
    "    if not line.strip():\n",
    "        continue\n",
    "    values = [v.strip() for v in line.split(\"|\")]\n",
    "    record = dict(zip(headers, values))\n",
    "    records.append(record)\n",
    "\n",
    "\n",
    "prompt_text, spec = render(\n",
    "    \"tot_reasoning.v2\",\n",
    "    role=\"SOS call analyzer\",\n",
    "    branches= 3,\n",
    "    problem = records,\n",
    "    branching_logic = \"Branch 1: Save the highest score first (Greedy),Branch 2: Save closest first (speed), Branch 3: Save furthest first (Logistics).\",\n",
    ")\n",
    "\n",
    "messages = [{\"role\": \"user\", \"content\": prompt_text}]\n",
    "response = llm_client.chat(messages, temperature=1.0)\n",
    "\n",
    "response_text = response[\"text\"]\n",
    "print(response_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prompt-engineering-essentials (3.13.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
